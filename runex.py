from flask import Flask, request, jsonify
from flask_cors import CORS
import psycopg2
from psycopg2.extras import RealDictCursor
from anthropic import Anthropic
import json
import logging
import traceback
import re
from sentence_transformers import SentenceTransformer, util
import numpy as np
import torch



app = Flask(__name__)
CORS(app)

DB_CONFIG = {
    "host": "rds-postgresql-pgvector.cbq4y662mptt.ap-northeast-2.rds.amazonaws.com",
    "user": "root",
    "password": "rkdtmdwls123",
    "dbname": "postgres",
    "port": 5432
}

client = Anthropic(api_key="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")

# ============================================================
# ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
# ============================================================
kure_model = SentenceTransformer('nlpai-lab/KURE-v1')

# ============================================================
# ì‹ ë¢°ë„ ê³„ì‚° ê´€ë ¨ ìƒìˆ˜ ë° ìœ í‹¸ë¦¬í‹°
# ============================================================

NULL_TOKENS = {"", ",", ";", "/", "-", "ëª¨ë¦„", "ë¬´ì‘ë‹µ", "ëª¨ë¦„/ë¬´ì‘ë‹µ", "í•´ë‹¹ì—†ìŒ", None}

INCOME_RANK = {
    "ì›” 100ë§Œì› ë¯¸ë§Œ": 1,
    "ì›” 100~199ë§Œì›": 2,
    "ì›” 200~299ë§Œì›": 3,
    "ì›” 300~399ë§Œì›": 4,
    "ì›” 400~499ë§Œì›": 5,
    "ì›” 500~599ë§Œì›": 6,
    "ì›” 600~699ë§Œì›": 7,
    "ì›” 700~799ë§Œì›": 8,
    "ì›” 800~899ë§Œì›": 9,
    "ì›” 900~999ë§Œì›": 10,
    "ì›” 1000ë§Œì› ì´ìƒ": 11,
    "ëª¨ë¦„/ë¬´ì‘ë‹µ": None,
    "": None    
}

RULE_MESSAGES = {
    "required_birth_year_missing": "í•„ìˆ˜ì •ë³´ ëˆ„ë½ : ë‚˜ì´",
    "required_occupation_missing": "í•„ìˆ˜ì •ë³´ ëˆ„ë½ : ì§ì—…",
    "required_income_missing": "í•„ìˆ˜ì •ë³´ ëˆ„ë½ : ê°œì¸ì†Œë“",
    "age_married_under18": "18ì„¸ ë¯¸ë§Œì¸ë° ê²°í˜¼ ìƒíƒœ",
    "age_child_under18": "18ì„¸ ë¯¸ë§Œì¸ë° ìë…€ ìˆìŒ",
    "age_college_under18": "18ì„¸ ë¯¸ë§Œì¸ë° ëŒ€í•™ ì¬í•™/ì¡¸ì—… ì´ìƒ",
    "age_car_under18_hascar": "ë§Œ 18ì„¸ ë¯¸ë§Œ ì°¨ëŸ‰ ë³´ìœ ",
    "age_car_under18_maker_filled": "ë§Œ 18ì„¸ ë¯¸ë§Œì¸ë° ìë™ì°¨ ì œì¡°ì‚¬ ê¸°ì…",
    "age_car_under18_model_filled": "ë§Œ 18ì„¸ ë¯¸ë§Œì¸ë° ìë™ì°¨ ëª¨ë¸ ê¸°ì…",
    "old_student_80plus": "80ì„¸ ì´ìƒì¸ë° í•™ìƒ",
    "born_before_1990_secondary_student": "1990ë…„ ì´ì „ ì¶œìƒì¸ë° ì¤‘/ê³ ë“±í•™ìƒ",
    "teen_smoker": "ë¯¸ì„±ë…„ í¡ì—° ê²½í—˜",
    "teen_drink": "ë¯¸ì„±ë…„ ìŒì£¼ ê²½í—˜",
    "brand_without_smoke": "í¡ì—°ê²½í—˜ ì—†ìŒì¸ë° ë‹´ë°°ë¸Œëœë“œ ì„ íƒ",
    "brand_etc_without_smoke": "í¡ì—°ê²½í—˜ ì—†ìŒì¸ë° ë‹´ë°°ë¸Œëœë“œ ê¸°íƒ€ë‚´ìš© ì…ë ¥",
    "heat_e_cig_without_smoke": "í¡ì—°ê²½í—˜ ì—†ìŒì¸ë° ê°€ì—´ì‹/ì „ìë‹´ë°° ì„ íƒ",
    "alcohol_memo_without_drink": "ìŒìš©ê²½í—˜ ì—†ìŒì¸ë° ìˆ  ê¸°íƒ€ë‚´ìš© ì…ë ¥",
    "lowedu_projob": "ê³ ì¡¸ ì´í•˜ì¸ë° ì „ë¬¸ì§",
    "personal_gt_household": "ì›” ê°œì¸ì†Œë“ > ì›” ê°€êµ¬ì†Œë“",
    "phone_brand_model_mismatch": "íœ´ëŒ€í° ë¸Œëœë“œ/ëª¨ë¸ ë¶ˆì¼ì¹˜",
    "old_student_flag": "50ì„¸ ì´ìƒì¸ë° ëŒ€í•™ìƒ/ëŒ€í•™ì›ìƒ",
    "car_brand_but_no_model": "ì°¨ëŸ‰ ë¸Œëœë“œ ìˆìŒ + ì°¨ì¢… ì—†ìŒ",
    "car_model_but_no_brand": "ì°¨ëŸ‰ ë¸Œëœë“œ ì—†ìŒ + ì°¨ì¢… ìˆìŒ",
    "car_have_N_but_brand_or_model": "ì°¨ëŸ‰ ë³´ìœ  'ì—†ë‹¤'ì¸ë° ë¸Œëœë“œ/ëª¨ë¸ ê¸°ì¬",
    "car_brand_model_mismatch_heuristic": "ì°¨ëŸ‰ ë¸Œëœë“œ/ëª¨ë¸ ë¶ˆì¼ì¹˜(íœ´ë¦¬ìŠ¤í‹±)",
}

# ìƒí™œíŒ¨í„´ ì¹¼ëŸ¼ ë¦¬ìŠ¤íŠ¸
LIFESTYLE_COLUMNS = [
    "ì²´ë ¥_ê´€ë¦¬ë¥¼_ìœ„í•œ_í™œë™",
    "ì´ìš©_ì¤‘ì¸_OTT_ì„œë¹„ìŠ¤",
    "ì „í†µì‹œì¥_ë°©ë¬¸_ë¹ˆë„",
    "ì„ í˜¸í•˜ëŠ”_ì„¤_ì„ ë¬¼_ìœ í˜•",
    "ì´ˆë“±í•™ìƒ_ì‹œì ˆ_ê²¨ìš¸ë°©í•™_ë•Œ_ê¸°ì–µì—_ë‚¨ëŠ”_ì¼",
    "ë°˜ë ¤ë™ë¬¼ì„_í‚¤ìš°ê±°ë‚˜_í‚¤ì› ë˜_ê²½í—˜",
    "ì´ì‚¬í• _ë•Œ_ìŠ¤íŠ¸ë ˆìŠ¤_ë°›ëŠ”_ë¶€ë¶„",
    "ë³¸ì¸ì„_ìœ„í•´_ì†Œë¹„í•˜ëŠ”_ê²ƒ_ì¤‘_ê¸°ë¶„_ì¢‹ì•„ì§€ëŠ”_ì†Œë¹„",
    "ìš”ì¦˜_ë§ì´_ì‚¬ìš©í•˜ëŠ”_ì•±",
    "ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼_ë§ì´_ëŠë¼ëŠ”_ìƒí™©",
    "ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼_í•´ì†Œí•˜ëŠ”_ë°©ë²•",
    "ë³¸ì¸_í”¼ë¶€_ìƒíƒœì—_ëŒ€í•œ_ë§Œì¡±ë„",
    "í•œ_ë‹¬_ê¸°ì¤€ìœ¼ë¡œ_ìŠ¤í‚¨ì¼€ì–´_ì œí’ˆì—_ì†Œë¹„í•˜ëŠ”_ì •ë„",
    "ìŠ¤í‚¨ì¼€ì–´_ì œí’ˆì„_êµ¬ë§¤í• _ë•Œ_ì¤‘ìš”í•˜ê²Œ_ê³ ë ¤í•˜ëŠ”_ìš”ì†Œ",
    "ì‚¬ìš©í•´_ë³¸_AI_ì±—ë´‡_ì„œë¹„ìŠ¤",
    "ì‚¬ìš©í•´_ë³¸_AI_ì±—ë´‡_ì„œë¹„ìŠ¤_ì¤‘_ì£¼ë¡œ_ì‚¬ìš©í•˜ëŠ”_ê²ƒ",
    "AI_ì±—ë´‡_ì„œë¹„ìŠ¤ë¥¼_í™œìš©í•œ_ìš©ë„ë‚˜_ì•ìœ¼ë¡œì˜_í™œìš©_ì—¬ë¶€",
    "ë‘_ì„œë¹„ìŠ¤_ì¤‘_ë”_í˜¸ê°ì´_ê°€ëŠ”_ì„œë¹„ìŠ¤",
    "í•´ì™¸ì—¬í–‰ì„_ê°„ë‹¤ë©´_ê°€ê³ ì‹¶ì€_ê³³",
    "ë¹ ë¥¸_ë°°ì†¡(ë‹¹ì¼Â·ìƒˆë²½Â·ì§ì§„_ë°°ì†¡)_ì„œë¹„ìŠ¤ë¥¼_ì–´ë–¤_ì œí’ˆì„_êµ¬ë§¤í• _ë•Œ_ì´ìš©í•˜ëŠ”ì§€",
    "ì—¬ë¦„ì² _ê°€ì¥_ê±±ì •ë˜ëŠ”_ì ",
    "ë²„ë¦¬ê¸°_ì•„ê¹Œìš´_ë¬¼ê±´ì´_ìˆì„_ë•Œ_ì–´ë–»ê²Œ_í•˜ëŠ”ì§€",
    "ì•„ì¹¨ì—_ê¸°ìƒí•˜ê¸°_ìœ„í•´_ì•ŒëŒì„_ì„¤ì •í•´ë‘ëŠ”_ë°©ì‹",
    "ì™¸ë¶€_ì‹ë‹¹ì—ì„œ_í˜¼ì_ì‹ì‚¬í•˜ëŠ”_ë¹ˆë„",
    "ê°€ì¥_ì¤‘ìš”í•˜ë‹¤ê³ _ìƒê°í•˜ëŠ”_í–‰ë³µí•œ_ë…¸ë…„ì˜_ì¡°ê±´",
    "ì—¬ë¦„ì² _ë•€_ë•Œë¬¸ì—_ê²ªëŠ”_ë¶ˆí¸í•¨",
    "ê°€ì¥_íš¨ê³¼_ìˆì—ˆë˜_ë‹¤ì´ì–´íŠ¸_ë°©ë²•",
    "ì•¼ì‹ì„_ë¨¹ëŠ”_ë°©ë²•",
    "ì—¬ë¦„ì² _ìµœì• _ê°„ì‹",
    "ìµœê·¼_ì§€ì¶œì„_ë§ì´_í•œ_ê³³",
    "AI_ì„œë¹„ìŠ¤ë¥¼_í™œìš©í•˜ëŠ”_ë¶„ì•¼",
    "ë³¸ì¸ì´_ë¯¸ë‹ˆë©€ë¦¬ìŠ¤íŠ¸ì™€_ë§¥ì‹œë©€ë¦¬ìŠ¤íŠ¸_ì¤‘_ì–´ëŠ_ìª½ì—_ê°€ê¹Œìš´ì§€",
    "ì—¬í–‰_ê°ˆ_ë•Œì˜_ìŠ¤íƒ€ì¼",
    "ì¼íšŒìš©_ë¹„ë‹ë´‰íˆ¬_ì‚¬ìš©ì„_ì¤„ì´ê¸°_ìœ„í•œ_ë…¸ë ¥",
    "í• ì¸,_ìºì‹œë°±,_ë©¤ë²„ì‹­_ë“±_í¬ì¸íŠ¸_ì ë¦½_í˜œíƒì„_ì‹ ê²½_ì“°ëŠ”_ì •ë„",
    "ì´ˆì½œë¦¿ì„_ë¨¹ëŠ”_ë•Œ",
    "ê°œì¸ì •ë³´_ë³´í˜¸ë¥¼_ìœ„í•œ_ìŠµê´€",
    "ì ˆëŒ€_í¬ê¸°í• _ìˆ˜_ì—†ëŠ”_ì—¬ë¦„_íŒ¨ì…˜_í•„ìˆ˜í…œ",
    "ê°‘ì‘ìŠ¤ëŸ°_ë¹„ê°€_ì˜¤ëŠ”ë°_ìš°ì‚°ì´_ì—†ëŠ”_ê²½ìš°_ì·¨í•˜ëŠ”_í–‰ë™",
    "íœ´ëŒ€í°_ê°¤ëŸ¬ë¦¬ì—_ê°€ì¥_ë§ì´_ì €ì¥ë˜ì–´_ìˆëŠ”_ì‚¬ì§„",
    "ì—¬ë¦„ì² _ë¬¼ë†€ì´_ì¥ì†Œë¡œ_ì„ í˜¸í•˜ëŠ”_ê³³"
]

# ì°¨ëŸ‰ ë¸Œëœë“œ ì •ê·œí™” ë§¤í•‘
_CAR_BRAND_ALIASES = {
    "í˜„ëŒ€": {"í˜„ëŒ€", "í˜„ëŒ€ìë™ì°¨", "hyundai"},
    "ê¸°ì•„": {"ê¸°ì•„", "ê¸°ì•„ìë™ì°¨", "kia"},
    "ì œë„¤ì‹œìŠ¤": {"ì œë„¤ì‹œìŠ¤", "genesis"},
    "ë¥´ë…¸ì½”ë¦¬ì•„": {"ë¥´ë…¸ì½”ë¦¬ì•„", "ë¥´ë…¸ì‚¼ì„±", "ë¥´ë…¸", "renault", "renault samsung", "renault korea"},
    "ì‰ë³´ë ˆ": {"ì‰ë³´ë ˆ", "chevrolet", "gm", "gmëŒ€ìš°", "ëŒ€ìš°"},
    "ìŒìš©": {"ìŒìš©", "ìŒìš©ìë™ì°¨", "kgëª¨ë¹Œë¦¬í‹°", "kg mobility", "ssangyong"},
    "ë©”ë¥´ì„¸ë°ìŠ¤-ë²¤ì¸ ": {"ë©”ë¥´ì„¸ë°ìŠ¤-ë²¤ì¸ ", "ë²¤ì¸ ", "mercedes", "mercedes-benz", "m-benz"},
    "BMW": {"bmw", "ë¹„ì— ë”ë¸”ìœ ", "ë¹„ì— "},
    "ì•„ìš°ë””": {"audi", "ì•„ìš°ë””"},
    "í­ìŠ¤ë°”ê²": {"vw", "volkswagen", "í­ìŠ¤ë°”ê²"},
    "í† ìš”íƒ€": {"toyota", "í† ìš”íƒ€"},
    "í˜¼ë‹¤": {"honda", "í˜¼ë‹¤"},
    "ë‹›ì‚°": {"nissan", "ë‹›ì‚°"},
    "ë ‰ì„œìŠ¤": {"lexus", "ë ‰ì„œìŠ¤"},
    "í¬ë¥´ì‰": {"porsche", "í¬ë¥´ì‰"},
}

# ì°¨ëŸ‰ ëª¨ë¸ íŒ¨í„´
_CAR_BRAND_MODEL_PATTERNS = {
    "í˜„ëŒ€": [
        r"\b(ì•„ë°˜ë–¼|ì˜ë‚˜íƒ€|ê·¸ëœì €|íˆ¬ì‹¼|ì‹¼íƒ€í˜|íŒ°ë¦¬ì„¸ì´ë“œ|ë² ë‰´|ìºìŠ¤í¼|ì½”ë‚˜|ì•„ì´ì˜¤ë‹‰|ë„¥ì˜)\b",
        r"\b(IONIQ|NEXO|SANTA\s?FE|PALISADE|TUCSON|KONA|AVANTE|SONATA|GRANDEUR)\b",
    ],
    "ê¸°ì•„": [
        r"\b(K[3-9]|K\d{1,2}|ì˜ë Œí† |ìŠ¤í¬í‹°ì§€|ëª¨ë‹|ë ˆì´|ë‹ˆë¡œ|ì¹´ë‹ˆë°œ|EV\d+|EV[36])\b",
        r"\b(SORENTO|SPORTAGE|CARNIVAL|MORNING|RAY|NIRO)\b",
    ],
    "ì œë„¤ì‹œìŠ¤": [r"\b(GV?\d{2}|G70|G80|G90|GV60|GV70|GV80|GV90)\b"],
    "ë¥´ë…¸ì½”ë¦¬ì•„": [r"\b(QM\d|XM3|SM\d|SM6)\b"],
    "ì‰ë³´ë ˆ": [
        r"\b(ìŠ¤íŒŒí¬|ë§ë¦¬ë¶€|ì„íŒ”ë¼|íŠ¸ë™ìŠ¤|ì´ì¿¼ë…¹ìŠ¤|íŠ¸ë˜ë²„ìŠ¤|ì½œë¡œë¼ë„|íƒ€í˜¸|ì¹´ë§ˆë¡œ|íŠ¸ë ˆì¼ë¸”ë ˆì´ì €)\b",
        r"\b(SPARK|MALIBU|IMPALA|TRAX|EQUINOX|TRAVERSE|COLORADO|TAHOE|CAMARO|TRAILBLAZER)\b",
    ],
    "ìŒìš©": [r"\b(ë ‰ìŠ¤í„´|ì½”ë€ë„|í‹°ë³¼ë¦¬|í† ë ˆìŠ¤)\b", r"\b(REXTON|KORANDO|TIVOLI|TORRES)\b"],
    "ë©”ë¥´ì„¸ë°ìŠ¤-ë²¤ì¸ ": [r"\b([CES]\s?-?\d{2,3}|GL[ABC]?|GLE|GLS|S\s?CLASS|E\s?CLASS|C\s?CLASS|AMG|EQ[BS]?\d*)\b"],
    "BMW": [r"\b([1-8]\s?ì‹œë¦¬ì¦ˆ|[1-8]\s?Series|X[1-7]|M\d{1,3}|i\d|i3|i4|i5|i7|320|520)\b"],
    "ì•„ìš°ë””": [r"\b(A[1-8]|Q[2-8]|e-?tron)\b"],
    "í­ìŠ¤ë°”ê²": [r"\b(í‹°êµ¬ì•ˆ|ê³¨í”„|ì•„í…Œì˜¨|íŒŒì‚¬íŠ¸|TIGUAN|GOLF|ARTEON|PASSAT)\b"],
    "í† ìš”íƒ€": [r"\b(ìº ë¦¬|ì½”ë¡¤ë¼|ë¼ë¸Œ4|í”„ë¦¬ìš°ìŠ¤|GR86|CAMRY|COROLLA|RAV4|PRIUS)\b"],
    "í˜¼ë‹¤": [r"\b(ì–´ì½”ë“œ|ì‹œë¹…|CR-?V|HR-?V|ACCORD|CIVIC|CRV|HRV)\b"],
    "ë‹›ì‚°": [r"\b(ì•Œí‹°ë§ˆ|ë¡œê·¸|ìºì‹œì¹´ì´|ë…¸íŠ¸|ë¦¬í”„|ALTIMA|ROGUE|QASHQAI|LEAF)\b"],
    "ë ‰ì„œìŠ¤": [r"\b(ES\d*|RX\d*|NX\d*|UX\d*|IS\d*|LS\d*)\b"],
    "í¬ë¥´ì‰": [r"\b(911|ì¹´ì´ì—”|ë§ˆì¹¸|íŒŒë‚˜ë©”ë¼|íƒ€ì´ì¹¸|CAYENNE|MACAN|PANAMERA|TAYCAN)\b"],
}

def norm_str(x):
    """ë¬¸ìì—´ ì •ê·œí™” (int/float íƒ€ì…ë„ ì²˜ë¦¬)"""
    if x is None:
        return ""
    if isinstance(x, (int, float)):
        return str(x)
    s = str(x).strip()
    if all(ch in {',',';','/','-','Â·','.'} for ch in s):
        return ""
    return s

def is_meaningful_text(x):
    """ì˜ë¯¸ìˆëŠ” í…ìŠ¤íŠ¸ì¸ì§€ í™•ì¸"""
    s = norm_str(x)
    return s not in NULL_TOKENS and s != ""

def norm_list(xs):
    """ë¦¬ìŠ¤íŠ¸ ì •ê·œí™”"""
    if xs is None: return []
    if isinstance(xs, str): xs = [xs]
    out = []
    for x in xs:
        s = norm_str(x)
        if is_meaningful_text(s):
            out.append(s)
    return out

def _norm_text_none(x):
    """None-safe í…ìŠ¤íŠ¸ ì •ê·œí™”"""
    s = str(x).strip() if x is not None else ""
    return s if s else None

def _canonical_car_brand(brand_text):
    """ì°¨ëŸ‰ ë¸Œëœë“œ ì •ê·œí™”"""
    b = _norm_text_none(brand_text)
    if b is None:
        return None
    bl = b.lower()
    for canon, aliases in _CAR_BRAND_ALIASES.items():
        for a in aliases:
            if bl == a.lower():
                return canon
    return b

def _guess_brands_from_model(model_text):
    """ëª¨ë¸ëª…ì—ì„œ ë¸Œëœë“œ ì¶”ì •"""
    m = _norm_text_none(model_text)
    if m is None:
        return set()
    u = m.upper()
    hits = set()
    for brand, pats in _CAR_BRAND_MODEL_PATTERNS.items():
        if any(re.search(p, u, flags=re.IGNORECASE) for p in pats):
            hits.add(brand)
    return hits

def _car_model_matches_brand(brand_text, model_text):
    """ì°¨ëŸ‰ ë¸Œëœë“œ-ëª¨ë¸ ì¼ì¹˜ í™•ì¸"""
    brand = _canonical_car_brand(brand_text)
    model = _norm_text_none(model_text)
    if not brand or not model:
        return None
    cand = _guess_brands_from_model(model)
    if len(cand) == 0:
        return None
    if len(cand) == 1:
        return (brand == next(iter(cand)))
    return None

def _brand_group_from_text(brand):
    """íœ´ëŒ€í° ë¸Œëœë“œ ê·¸ë£¹ íŒë³„"""
    b = brand
    if not b: return None
    if "ì• í”Œ" in b or "Apple" in b or "ì•„ì´í°" in b: return "apple"
    if "ì‚¼ì„±" in b or "ê°¤ëŸ­ì‹œ" in b or "Galaxy" in b or "ë…¸íŠ¸" in b: return "samsung"
    if "LG" in b: return "lg"
    if "ìƒ¤ì˜¤ë¯¸" in b or "Xiaomi" in b or "í¬ì½”" in b or "í™ë¯¸" in b or "ë ˆë“œë¯¸" in b: return "xiaomi"
    if "ê¸°íƒ€" in b: return "etc"
    return None

def _model_group_from_text(model):
    """íœ´ëŒ€í° ëª¨ë¸ ê·¸ë£¹ íŒë³„"""
    m = model
    if not m: return None
    if "í´ë”í°" in m or "ë³´ìœ  X" in m or ("ê¸°íƒ€" in m and "ì•„ì´í°" not in m and "ê°¤ëŸ­ì‹œ" not in m and "LG" not in m and "ìƒ¤ì˜¤ë¯¸" not in m):
        return "special"
    if "ì•„ì´í°" in m: return "apple"
    if "ê°¤ëŸ­ì‹œ" in m or "Galaxy" in m or "ë…¸íŠ¸" in m or "Z Fold" in m or "Z Flip" in m: return "samsung"
    if "LG" in m or "V ì‹œë¦¬ì¦ˆ" in m or "G ì‹œë¦¬ì¦ˆ" in m: return "lg"
    if "ìƒ¤ì˜¤ë¯¸" in m or "í¬ì½”" in m or "í™ë¯¸" in m or "ë ˆë“œë¯¸" in m: return "xiaomi"
    return None

def _any_smoke_selected(smoke_set):
    """í¡ì—° ê²½í—˜ ì²´í¬"""
    items = norm_list(smoke_set)
    NEG_SMOKE = "ë‹´ë°°ë¥¼ í”¼ì›Œë³¸ ì ì´ ì—†ë‹¤"
    for s in items:
        if NEG_SMOKE in s:
            continue
        return True
    return False

def _is_under(n, limit):
    """ë‚˜ì´ ë¯¸ë§Œ ì²´í¬"""
    return (n is not None) and (n < limit)

def _is_overeq(n, limit):
    """ë‚˜ì´ ì´ìƒ ì²´í¬"""
    return (n is not None) and (n >= limit)

def _get(row, key, default=None):
    """ì•ˆì „í•œ ë”•ì…”ë„ˆë¦¬ ì ‘ê·¼"""
    return row.get(key, default)

# ============================================================
# íŒ¨ë„ ë°ì´í„° ì „ì²˜ë¦¬
# ============================================================

def preprocess_panel(row):
    """íŒ¨ë„ ë°ì´í„° ì „ì²˜ë¦¬ ë° ë©”íƒ€ë°ì´í„° ìƒì„±"""
    r = dict(row)

    # ë‚˜ì´ ê³„ì‚° (ì¼ë°˜ ë‚˜ì´)
    birth = _get(r, "ì¶œìƒë…„ë„")
    try:
        if isinstance(birth, int):
            birth_int = birth
        else:
            birth_int = int(str(birth).strip())
        r["age"] = 2025 - birth_int - 1  # ë§Œ ë‚˜ì´
    except Exception:
        r["age"] = None

    # ê°€ì¡±ìˆ˜ ì •ê·œí™”
    fam_text = norm_str(_get(r, "ê°€ì¡±ìˆ˜"))
    fam_map = {"1ëª…(í˜¼ì ê±°ì£¼)": 1, "2ëª…": 2, "3ëª…": 3, "4ëª…": 4, "5ëª… ì´ìƒ": 5}
    r["_ê°€ì¡±ìˆ˜_ìˆ˜ì¹˜"] = fam_map.get(fam_text, None)
    
    # ìë…€ìˆ˜ ì•ˆì „ ì²˜ë¦¬
    children = _get(r, "ìë…€ìˆ˜")
    if isinstance(children, int):
        r["_ìë…€ìˆ˜"] = children
    elif children:
        try:
            r["_ìë…€ìˆ˜"] = int(norm_str(children))
        except:
            r["_ìë…€ìˆ˜"] = 0
    else:
        r["_ìë…€ìˆ˜"] = 0

    # ê¸°ë³¸ ì •ë³´ ì •ê·œí™”
    r["_í•™ë ¥"] = norm_str(_get(r, "ìµœì¢…í•™ë ¥"))
    r["_ì§ì—…"] = norm_str(_get(r, "ì§ì—…"))
    r["_ê²°í˜¼"] = norm_str(_get(r, "ê²°í˜¼ì—¬ë¶€"))

    # ì†Œë“ ë­í¬
    r["_ê°œì¸ì†Œë“_ë­í¬"] = INCOME_RANK.get(norm_str(_get(r, "ì›”í‰ê· _ê°œì¸ì†Œë“")), None)
    r["_ê°€êµ¬ì†Œë“_ë­í¬"] = INCOME_RANK.get(norm_str(_get(r, "ì›”í‰ê· _ê°€êµ¬ì†Œë“")), None)

    # ë©€í‹°ì„ íƒ ì •ê·œí™”
    r["_í¡ì—°_set"] = norm_list(_get(r, "í¡ì—°ê²½í—˜", []))
    r["_ë‹´ë°°ë¸Œëœë“œ_set"] = norm_list(_get(r, "í¡ì—°ê²½í—˜_ë‹´ë°°ë¸Œëœë“œ", []))
    r["_ê°€ì—´ì‹_set"] = norm_list(_get(r, "ì „ìë‹´ë°°_ì´ìš©ê²½í—˜", []))
    r["_ì£¼ë¥˜_set"] = norm_list(_get(r, "ìŒìš©ê²½í—˜_ìˆ ", []))

    # ETC í”Œë˜ê·¸
    r["_ë‹´ë°°ë¸Œëœë“œ_ETC"] = is_meaningful_text(_get(r, "í¡ì—°ê²½í—˜_ë‹´ë°°ë¸Œëœë“œ_ê¸°íƒ€"))
    r["_ê°€ì—´ì‹_ETC"] = is_meaningful_text(_get(r, "í¡ì—°ê²½í—˜_ë‹´ë°°_ê¸°íƒ€ë‚´ìš©"))
    r["_ìˆ _ETC"] = is_meaningful_text(_get(r, "ìŒìš©ê²½í—˜_ìˆ _ê¸°íƒ€ë‚´ìš©"))

    # íœ´ëŒ€í° ì •ë³´
    r["_í°ë¸Œëœë“œ"] = norm_str(_get(r, "íœ´ëŒ€í°_ë¸Œëœë“œ"))
    r["_í°ëª¨ë¸"] = norm_str(_get(r, "íœ´ëŒ€í°_ëª¨ë¸"))

    # ì°¨ëŸ‰ ì •ë³´
    r["_ì°¨ëŸ‰ë³´ìœ "] = norm_str(_get(r, "ì°¨ëŸ‰ì—¬ë¶€"))
    r["_ì œì¡°ì‚¬"] = _norm_text_none(_get(r, "ìë™ì°¨_ì œì¡°ì‚¬"))
    r["_ì°¨ëª¨ë¸"] = _norm_text_none(_get(r, "ìë™ì°¨_ëª¨ë¸"))

    return r

# ============================================================
# ì‹ ë¢°ë„ ê·œì¹™ ì •ì˜
# ============================================================

def get_reliability_rules():
    """ì‹ ë¢°ë„ ê²€ì¦ ê·œì¹™ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"""
    return [
        ("required_birth_year_missing",
         lambda r: not r.get("ì¶œìƒë…„ë„") or r.get("ì¶œìƒë…„ë„") in ["", "-", None, "ë¬´ì‘ë‹µ"]),
        
        ("required_occupation_missing",
         lambda r: not r.get("ì§ì—…") or r.get("ì§ì—…") in ["", "-", None, "ë¬´ì‘ë‹µ"]),
        
        ("required_income_missing",
         lambda r: not r.get("ì›”í‰ê· _ê°œì¸ì†Œë“") or r.get("ì›”í‰ê· _ê°œì¸ì†Œë“") in ["", "-", None, "ë¬´ì‘ë‹µ"]),
        
        ("age_married_under18",
         lambda r: _is_under(r.get("age"), 18) and (r["_ê²°í˜¼"] in ["ê¸°í˜¼", "ê¸°íƒ€(ì‚¬ë³„/ì´í˜¼ ë“±)"])),
        
        ("age_child_under18",
         lambda r: _is_under(r.get("age"), 18) and (r.get("_ìë…€ìˆ˜", 0) > 0)),
        
        ("age_college_under18",
         lambda r: _is_under(r.get("age"), 18) and (r["_í•™ë ¥"] in ["ëŒ€í•™êµ ì¬í•™(íœ´í•™ í¬í•¨)", "ëŒ€í•™êµ ì¡¸ì—…", "ëŒ€í•™ì› ì¬í•™/ì¡¸ì—… ì´ìƒ"])),

        ("old_student_80plus",
         lambda r: _is_overeq(r.get("age"), 80) and (r["_ì§ì—…"] in ["ì¤‘/ê³ ë“±í•™ìƒ", "ëŒ€í•™ìƒ/ëŒ€í•™ì›ìƒ"])),

        ("age_car_under18_hascar",
         lambda r: _is_under(r.get("age"), 18) and (r["_ì°¨ëŸ‰ë³´ìœ "] == "ìˆë‹¤")),
        
        ("age_car_under18_maker_filled",
         lambda r: _is_under(r.get("age"), 18) and bool(r["_ì œì¡°ì‚¬"])),
        
        ("age_car_under18_model_filled",
         lambda r: _is_under(r.get("age"), 18) and bool(r["_ì°¨ëª¨ë¸"])),

        ("teen_smoker",
         lambda r: _is_under(r.get("age"), 19) and _any_smoke_selected(r["_í¡ì—°_set"])),
        
        ("teen_drink",
         lambda r: _is_under(r.get("age"), 19) and any(a for a in r["_ì£¼ë¥˜_set"] if "ìµœê·¼ 1ë…„ ì´ë‚´ ìˆ ì„ ë§ˆì‹œì§€ ì•ŠìŒ" not in a)),

        ("brand_without_smoke",
         lambda r: (len(r["_í¡ì—°_set"]) == 0 or not _any_smoke_selected(r["_í¡ì—°_set"])) and len(r["_ë‹´ë°°ë¸Œëœë“œ_set"]) > 0),
        
        ("brand_etc_without_smoke",
         lambda r: (len(r["_í¡ì—°_set"]) == 0 or not _any_smoke_selected(r["_í¡ì—°_set"])) and r["_ë‹´ë°°ë¸Œëœë“œ_ETC"]),
        
        ("heat_e_cig_without_smoke",
         lambda r: (len(r["_í¡ì—°_set"]) == 0 or not _any_smoke_selected(r["_í¡ì—°_set"])) and (len(r["_ê°€ì—´ì‹_set"]) > 0 or r["_ê°€ì—´ì‹_ETC"])),
        
        ("alcohol_memo_without_drink",
         lambda r: (len(r["_ì£¼ë¥˜_set"]) == 0 or all("ìµœê·¼ 1ë…„ ì´ë‚´ ìˆ ì„ ë§ˆì‹œì§€ ì•ŠìŒ" in a for a in r["_ì£¼ë¥˜_set"])) and r["_ìˆ _ETC"]),

        ("lowedu_projob",
         lambda r: (r["_í•™ë ¥"] in ["ê³ ë“±í•™êµ ì¡¸ì—… ì´í•˜"]) and (r["_ì§ì—…"] == "ì „ë¬¸ì§ (ì˜ì‚¬, ê°„í˜¸ì‚¬, ë³€í˜¸ì‚¬, íšŒê³„ì‚¬, ì˜ˆìˆ ê°€, ì¢…êµì¸, ì—”ì§€ë‹ˆì–´, í”„ë¡œê·¸ë˜ë¨¸, ê¸°ìˆ ì‚¬ ë“±)")),

        ("personal_gt_household",
         lambda r: (r["_ê°œì¸ì†Œë“_ë­í¬"] is not None and r["_ê°€êµ¬ì†Œë“_ë­í¬"] is not None) and
                   (r["_ê°œì¸ì†Œë“_ë­í¬"] > r["_ê°€êµ¬ì†Œë“_ë­í¬"])),

        ("phone_brand_model_mismatch",
         lambda r: (lambda bg, mg: (
             False if (bg is None or mg is None or mg == "special")
             else ((bg == "apple"   and mg != "apple") or
                   (bg == "samsung" and mg != "samsung") or
                   (bg == "lg"      and mg != "lg") or
                   (bg == "xiaomi"  and mg != "xiaomi"))
         ))(_brand_group_from_text(r["_í°ë¸Œëœë“œ"]),
            _model_group_from_text(r["_í°ëª¨ë¸"]))),

        ("old_student_flag",
         lambda r: (r.get("age") is not None) and (r["age"] >= 50) and (r["_ì§ì—…"] == "ëŒ€í•™ìƒ/ëŒ€í•™ì›ìƒ")),

        ("born_before_1990_secondary_student",
         lambda r: (
             (_get(r, "ì¶œìƒë…„ë„") and (
                 (isinstance(_get(r, "ì¶œìƒë…„ë„"), int) and _get(r, "ì¶œìƒë…„ë„") < 1990) or
                 (isinstance(_get(r, "ì¶œìƒë…„ë„"), str) and int(_get(r, "ì¶œìƒë…„ë„")) < 1990)
             )) and (r["_ì§ì—…"] == "ì¤‘/ê³ ë“±í•™ìƒ")
         )),

        ("car_brand_but_no_model",
         lambda r: bool(_norm_text_none(r.get("_ì œì¡°ì‚¬"))) and not _norm_text_none(r.get("_ì°¨ëª¨ë¸"))),

        ("car_model_but_no_brand",
         lambda r: not _norm_text_none(r.get("_ì œì¡°ì‚¬")) and bool(_norm_text_none(r.get("_ì°¨ëª¨ë¸")))),

        ("car_have_N_but_brand_or_model",
         lambda r: (r.get("_ì°¨ëŸ‰ë³´ìœ ") == "ì—†ë‹¤") and (bool(_norm_text_none(r.get("_ì œì¡°ì‚¬"))) or bool(_norm_text_none(r.get("_ì°¨ëª¨ë¸"))))),

        ("car_brand_model_mismatch_heuristic",
         lambda r: (lambda ok: (ok is False))(_car_model_matches_brand(r.get("_ì œì¡°ì‚¬"), r.get("_ì°¨ëª¨ë¸")))),
    ]

def calculate_reliability_score(row):
    rr = preprocess_panel(row)
    rules = get_reliability_rules()
    detail = {name: bool(fn(rr)) for name, fn in rules}
    hit_rules = [k for k, v in detail.items() if v]
    hit_messages = [RULE_MESSAGES.get(k, k) for k in hit_rules]

    required_missing_count = sum(1 for rule in ["required_birth_year_missing", "required_occupation_missing", "required_income_missing"] if rule in hit_rules)
    other_rules = [rule for rule in hit_rules if rule not in ["required_birth_year_missing", "required_occupation_missing", "required_income_missing"]]
    
    score = 100 - (26 * required_missing_count) - (5 * len(other_rules))
    score = max(0, score)
    
    return score, hit_rules, hit_messages

# ============================================================
# íŒ¨ë„ í…ìŠ¤íŠ¸í™”
# ============================================================

def panel_to_text(r):
    """íŒ¨ë„ ë°ì´í„°ë¥¼ ìì—°ì–´ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    parts = []
    
    gender = r.get("ì„±ë³„")
    if gender:
        parts.append(f"{gender}ì´ë‹¤.")
    
    birth = r.get("ì¶œìƒë…„ë„")
    age = r.get("age")
    if age:
        parts.append(f"{birth}ë…„ìƒìœ¼ë¡œ ë§Œ {age}ì„¸ì´ë‹¤.")
    elif birth:
        parts.append(f"{birth}ë…„ìƒì´ë‹¤.")
    
    region1 = r.get("ì§€ì—­")
    region2 = r.get("ì§€ì—­êµ¬")
    if region1 and region2:
        parts.append(f"{region1} {region2} ê±°ì£¼ìì´ë‹¤.")
    elif region1:
        parts.append(f"{region1} ê±°ì£¼ìì´ë‹¤.")
    
    personal = r.get("ì›”í‰ê· _ê°œì¸ì†Œë“")
    household = r.get("ì›”í‰ê· _ê°€êµ¬ì†Œë“")
    if personal:
        parts.append(f"ì›” ê°œì¸ì†Œë“ì€ {personal} ìˆ˜ì¤€ì´ë‹¤.")
    if household:
        parts.append(f"ì›” ê°€êµ¬ì†Œë“ì€ {household} ìˆ˜ì¤€ì´ë‹¤.")
    
    job = r.get("ì§ì—…")
    edu = r.get("ìµœì¢…í•™ë ¥")
    if job:
        parts.append(f"ì§ì—…ì€ {job}ì´ë‹¤.")
    if edu:
        parts.append(f"ìµœì¢…í•™ë ¥ì€ {edu}ì´ë‹¤.")
    
    car = r.get("ì°¨ëŸ‰ì—¬ë¶€")
    if car:
        parts.append(f"ì°¨ëŸ‰ ë³´ìœ  ì—¬ë¶€ëŠ” {car}ì´ë‹¤.")
    
    phone_brand = r.get("íœ´ëŒ€í°_ë¸Œëœë“œ")
    phone_model = r.get("íœ´ëŒ€í°_ëª¨ë¸")
    if phone_brand and phone_model:
        parts.append(f"{phone_brand}ì˜ {phone_model}ì„ ì‚¬ìš©í•˜ê³  ìˆë‹¤.")
    elif phone_brand:
        parts.append(f"{phone_brand} ìŠ¤ë§ˆíŠ¸í°ì„ ì‚¬ìš©í•˜ê³  ìˆë‹¤.")
    
    smokes = r.get("í¡ì—°ê²½í—˜") or []
    if smokes:
        smoke_str = ", ".join(smokes) if isinstance(smokes, list) else str(smokes)
        parts.append(f"í¡ì—°ê²½í—˜ìœ¼ë¡œëŠ” {smoke_str} ê²½í—˜ì´ ìˆë‹¤.")
    
    drinks = r.get("ìŒìš©ê²½í—˜_ìˆ ") or []
    if drinks:
        drink_str = ", ".join(drinks) if isinstance(drinks, list) else str(drinks)
        parts.append(f"ìŒì£¼ ê²½í—˜ìœ¼ë¡œëŠ” {drink_str} ê²½í—˜ì´ ìˆë‹¤.")
    
    return " ".join(parts)

# ============================================================
# ìƒí™œíŒ¨í„´ ì„ë² ë”© ê¸°ë°˜ íŒ¨ë„ID ì¶”ì¶œ
# ============================================================

def is_lifestyle_query(query: str) -> bool:
    """ì¿¼ë¦¬ê°€ ìƒí™œíŒ¨í„´ ê´€ë ¨ì¸ì§€ íŒë‹¨"""
    lifestyle_keywords = [
        'ìš´ë™', 'ì²´ë ¥', 'OTT', 'ë„·í”Œë¦­ìŠ¤', 'ë””ì¦ˆë‹ˆ', 'ì „í†µì‹œì¥', 'ì‹œì¥', 'ì„¤ì„ ë¬¼', 'ì„ ë¬¼',
        'ë°©í•™', 'ê²¨ìš¸ë°©í•™', 'ì¶”ì–µ', 'ë°˜ë ¤ë™ë¬¼', 'ê°•ì•„ì§€', 'ê³ ì–‘ì´', 'ì• ì™„ë™ë¬¼', 'ì´ì‚¬', 'ìŠ¤íŠ¸ë ˆìŠ¤',
        'ì†Œë¹„', 'ì‡¼í•‘', 'ì•±', 'ì–´í”Œ', 'í”¼ë¶€', 'ìŠ¤í‚¨ì¼€ì–´', 'í™”ì¥í’ˆ', 'AI', 'ì±—ë´‡', 'ì—¬í–‰',
        'í•´ì™¸ì—¬í–‰', 'ë°°ì†¡', 'ë‹¹ì¼ë°°ì†¡', 'ì—¬ë¦„', 'ë”ìœ„', 'ë¬¼ê±´', 'ì•ŒëŒ', 'í˜¼ë°¥', 'ë…¸ë…„', 'ë•€',
        'ë‹¤ì´ì–´íŠ¸', 'ì•¼ì‹', 'ê°„ì‹', 'ì§€ì¶œ', 'ë¯¸ë‹ˆë©€', 'ë§¥ì‹œë©€', 'ë¹„ë‹ë´‰íˆ¬', 'í™˜ê²½', 'í• ì¸',
        'í¬ì¸íŠ¸', 'ë©¤ë²„ì‹­', 'ì´ˆì½œë¦¿', 'ê°œì¸ì •ë³´', 'íŒ¨ì…˜', 'ìš°ì‚°', 'ê°¤ëŸ¬ë¦¬', 'ì‚¬ì§„', 'ë¬¼ë†€ì´'
    ]
    return any(keyword in query for keyword in lifestyle_keywords)

def get_lifestyle_based_panel_ids(query: str, top_k: int = 100):
    """ìƒí™œíŒ¨í„´ ì„ë² ë”© ê¸°ë°˜ìœ¼ë¡œ íŒ¨ë„ ID ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        # 1. ì „ì²´ íŒ¨ë„ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        conn = psycopg2.connect(**DB_CONFIG)
        cur = conn.cursor(cursor_factory=RealDictCursor)
        
        # ìƒí™œíŒ¨í„´ ì¹¼ëŸ¼ë§Œ ì„ íƒí•˜ì—¬ ì¿¼ë¦¬
        lifestyle_cols_quoted = ', '.join([f'"{col}"' for col in LIFESTYLE_COLUMNS])
        query_sql = f'SELECT "íŒ¨ë„id", {lifestyle_cols_quoted} FROM panel_cb_all'
        
        cur.execute(query_sql)
        all_panels = cur.fetchall()
        cur.close()
        conn.close()
        
        if not all_panels:
            return []
        
        logging.info(f"ğŸ” ìƒí™œíŒ¨í„´ ì„ë² ë”© ë¶„ì„: ì „ì²´ {len(all_panels)}ê°œ íŒ¨ë„")
        
        # 2. ì¿¼ë¦¬ ì„ë² ë”©
        query_embedding = kure_model.encode(query, convert_to_tensor=True)
        
        # 3. ê° íŒ¨ë„ì˜ ìƒí™œíŒ¨í„´ í…ìŠ¤íŠ¸ ìƒì„± ë° ìœ ì‚¬ë„ ê³„ì‚°
        panel_scores = []
        for panel in all_panels:
            lifestyle_texts = []
            for col in LIFESTYLE_COLUMNS:
                value = panel.get(col)
                if value and value not in NULL_TOKENS and str(value).strip():
                    lifestyle_texts.append(str(value))
            
            if lifestyle_texts:
                # ìƒí™œíŒ¨í„´ í…ìŠ¤íŠ¸ ê²°í•©
                combined_text = " ".join(lifestyle_texts)
                panel_embedding = kure_model.encode(combined_text, convert_to_tensor=True)
                
                # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
                similarity = util.pytorch_cos_sim(query_embedding, panel_embedding).item()
                panel_scores.append((panel.get('íŒ¨ë„id'), similarity))
        
        # 4. ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìƒìœ„ top_kê°œ íŒ¨ë„ ID ë°˜í™˜
        panel_scores.sort(key=lambda x: x[1], reverse=True)
        top_panel_ids = [panel_id for panel_id, score in panel_scores[:top_k]]
        
        logging.info(f"âœ… ìƒí™œíŒ¨í„´ ê¸°ë°˜ íŒ¨ë„ ID ì¶”ì¶œ ì™„ë£Œ: {len(top_panel_ids)}ê°œ")
        
        return top_panel_ids
        
    except Exception as e:
        logging.error(f"ğŸ’¥ ìƒí™œíŒ¨í„´ ì„ë² ë”© ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        traceback.print_exc()
        return []

# ============================================================
# SQL ìƒì„± í”„ë¡¬í”„íŠ¸
# ============================================================

def create_sql_generation_prompt(user_query: str, lifestyle_panel_ids: list = None) -> str:
    """SQL ì¿¼ë¦¬ ìƒì„± í”„ë¡¬í”„íŠ¸ (ìƒí™œíŒ¨í„´ ê¸°ë°˜ í•„í„°ë§ í¬í•¨)"""
    
    # ìƒí™œíŒ¨í„´ ê¸°ë°˜ íŒ¨ë„ IDê°€ ìˆìœ¼ë©´ IN ì ˆ ì¶”ê°€
    lifestyle_filter = ""
    if lifestyle_panel_ids:
        # SQL Injection ë°©ì§€ë¥¼ ìœ„í•´ íŒ¨ë„ IDë¥¼ ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬
        escaped_ids = [f"'{pid}'" for pid in lifestyle_panel_ids[:100]]  # ìƒìœ„ 100ê°œë§Œ
        lifestyle_filter = f"\nâš ï¸ ì¤‘ìš”: ìƒí™œíŒ¨í„´ ê¸°ë°˜ í•„í„°ë§ì´ ì ìš©ë©ë‹ˆë‹¤. WHERE ì ˆì— ë°˜ë“œì‹œ ë‹¤ìŒ ì¡°ê±´ì„ ì¶”ê°€í•˜ì„¸ìš”:\n\"íŒ¨ë„id\" IN ({', '.join(escaped_ids)})\n"
    
    return f"""ë‹¹ì‹ ì€ PostgreSQL SQL ì¿¼ë¦¬ ìƒì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

í…Œì´ë¸” ì´ë¦„: panel_cb_all

í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ (ì •í™•í•œ ì»¬ëŸ¼ëª…):
- íŒ¨ë„id (VARCHAR, PRIMARY KEY)
- ì„±ë³„ (VARCHAR) - ì˜ˆ: 'ë‚¨ì„±', 'ì—¬ì„±'
- ì¶œìƒë…„ë„ (VARCHAR) âš ï¸ ë¬¸ìì—´ì´ë¯€ë¡œ ìˆ«ì ë¹„êµì‹œ ë°˜ë“œì‹œ ::INTEGER ìºìŠ¤íŒ… í•„ìš”!
- ì§€ì—­ (VARCHAR) - ì˜ˆ: 'ì„œìš¸', 'ë¶€ì‚°', 'ê²½ê¸°', 'ì¸ì²œ' ë“±
- ì§€ì—­êµ¬ (VARCHAR)
- ê²°í˜¼ì—¬ë¶€ (VARCHAR) - ì˜ˆ: 'ê¸°í˜¼', 'ë¯¸í˜¼'
- ìë…€ìˆ˜ (INTEGER) - ì´ë¯¸ ìˆ«ìí˜•ì´ë¯€ë¡œ ìºìŠ¤íŒ… ë¶ˆí•„ìš”
- ê°€ì¡±ìˆ˜ (VARCHAR) - ìˆ«ì ë¹„êµì‹œ ::INTEGER ìºìŠ¤íŒ… í•„ìš”
- ìµœì¢…í•™ë ¥ (VARCHAR)
- ì§ì—… (VARCHAR)
- ì§ë¬´ (VARCHAR)
- ì›”í‰ê· _ê°œì¸ì†Œë“ (VARCHAR)
- ì›”í‰ê· _ê°€êµ¬ì†Œë“ (VARCHAR)
- ë³´ìœ ì „ì œí’ˆ (JSONB)
- íœ´ëŒ€í°_ë¸Œëœë“œ (VARCHAR)
- íœ´ëŒ€í°_ëª¨ë¸ (VARCHAR)
- ì°¨ëŸ‰ì—¬ë¶€ (VARCHAR) - ì˜ˆ: 'ìˆë‹¤', 'ì—†ë‹¤'
- ìë™ì°¨_ì œì¡°ì‚¬ (VARCHAR)
- ìë™ì°¨_ëª¨ë¸ (VARCHAR)
- í¡ì—°ê²½í—˜ (JSONB)
- ìŒìš©ê²½í—˜_ìˆ  (JSONB)
{lifestyle_filter}
ì‚¬ìš©ì ìš”ì²­: "{user_query}"

ì¿¼ë¦¬ ìƒì„± ê·œì¹™:
1. ê¸°ë³¸ í˜•ì‹: SELECT * FROM panel_cb_all
2. ì¶œìƒë…„ë„ë¡œ ë‚˜ì´ ê³„ì‚° ì‹œ ë°˜ë“œì‹œ ::INTEGER ìºìŠ¤íŒ…
3. ë‚˜ì´ëŒ€ë³„ ì¶œìƒë…„ë„ (2025ë…„ ê¸°ì¤€, ë§Œ ë‚˜ì´):
   - 10ëŒ€ (ë§Œ 10~19ì„¸): ì¶œìƒë…„ë„::INTEGER BETWEEN 2005 AND 2014
   - 20ëŒ€ (ë§Œ 20~29ì„¸): ì¶œìƒë…„ë„::INTEGER BETWEEN 1995 AND 2004
   - 30ëŒ€ (ë§Œ 30~39ì„¸): ì¶œìƒë…„ë„::INTEGER BETWEEN 1985 AND 1994
   - 40ëŒ€ (ë§Œ 40~49ì„¸): ì¶œìƒë…„ë„::INTEGER BETWEEN 1975 AND 1984
   - 50ëŒ€ (ë§Œ 50~59ì„¸): ì¶œìƒë…„ë„::INTEGER BETWEEN 1965 AND 1974
   - 60ëŒ€ (ë§Œ 60~69ì„¸): ì¶œìƒë…„ë„::INTEGER BETWEEN 1955 AND 1964
4. ì¸ì›ìˆ˜ ëª…ì‹œì‹œ LIMIT ì¶”ê°€
5. ê³ ì†Œë“ìëŠ” ì›”í‰ê· _ê°œì¸ì†Œë“ 400ë§Œì› ì´ìƒ
6. ìƒí™œíŒ¨í„´ í•„í„°ê°€ ìˆìœ¼ë©´ WHERE ì ˆì— \"íŒ¨ë„id\" IN (...) ì¡°ê±´ì„ ë°˜ë“œì‹œ í¬í•¨
7. ì—¬ëŸ¬ ì¡°ê±´ì´ ìˆì„ ë•ŒëŠ” ANDë¡œ ì—°ê²°

ì§€ê¸ˆ SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì„¸ìš” (ìˆœìˆ˜ SQLë§Œ):"""

# ============================================================
# API ì—”ë“œí¬ì¸íŠ¸
# ============================================================

@app.route('/api/search', methods=['POST'])
def search():
    try:
        data = request.get_json()
        query = data.get('query', '').strip()

        if not query:
            return jsonify({"error": "ì¿¼ë¦¬ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."}), 400

        logging.info(f"ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: {query}")

        # ìƒí™œíŒ¨í„´ ê´€ë ¨ ì¿¼ë¦¬ì¸ì§€ í™•ì¸ í›„ íŒ¨ë„ ID ì¶”ì¶œ
        lifestyle_panel_ids = None
        if is_lifestyle_query(query):
            logging.info("ğŸ¯ ìƒí™œíŒ¨í„´ ì„ë² ë”© ë¶„ì„ ì‹œì‘")
            lifestyle_panel_ids = get_lifestyle_based_panel_ids(query, top_k=100)
            
            if not lifestyle_panel_ids:
                logging.info("âŒ ìƒí™œíŒ¨í„´ ê¸°ë°˜ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                return jsonify({
                    "panels": [],
                    "words": []
                })

        # Claude APIë¡œ SQL ì¿¼ë¦¬ ìƒì„± (ìƒí™œíŒ¨í„´ íŒ¨ë„ ID í¬í•¨)
        message = client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=2048,
            messages=[
                {"role": "user", "content": create_sql_generation_prompt(query, lifestyle_panel_ids)}
            ]
        )
        
        sql_query = message.content[0].text.strip()
        
        # SQL ì¿¼ë¦¬ ì •ì œ
        if sql_query.startswith("```sql"):
            sql_query = sql_query[6:]
        if sql_query.startswith("```"):
            sql_query = sql_query[3:]
        if sql_query.endswith("```"):
            sql_query = sql_query[:-3]
        sql_query = sql_query.strip()
        
        logging.info(f"ğŸ“ ìƒì„±ëœ SQL: {sql_query}")
        
        # DB ì¡°íšŒ ì‹¤í–‰
        conn = psycopg2.connect(**DB_CONFIG)
        cur = conn.cursor(cursor_factory=RealDictCursor)
        cur.execute(sql_query)
        results = cur.fetchall()
        cur.close()
        conn.close()
        
        if not results:
            logging.info("âŒ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
            return jsonify({
                "panels": [],
                "words": []
            })
        
        logging.info(f"âœ… DB ì¡°íšŒ ì™„ë£Œ: {len(results)}ê°œ íŒ¨ë„")
        
        # ê²°ê³¼ ë³€í™˜
        panels = []
        for idx, row in enumerate(results, start=1):
            panel_dict = dict(row)
            
            score, hit_rules, hit_messages = calculate_reliability_score(panel_dict)
            
            birth_year = panel_dict.get('ì¶œìƒë…„ë„')
            age = None
            if birth_year:
                try:
                    age = 2025 - int(birth_year) -1
                except:
                    age = None
            
            def convert_null(value, default='ë¬´ì‘ë‹µ'):
                if value is None or value == '' or value == '-' or value == 'null':
                    return default
                return value
            
            lifestyle_dict = {}
            for f in LIFESTYLE_COLUMNS:
                lifestyle_dict[f] = convert_null(panel_dict.get(f))

            panel = {
                "id": f"íŒ¨ë„{idx}",
                "mbSn": convert_null(panel_dict.get('íŒ¨ë„id'), f"MB{idx}"),
                "reliability": score,
                "reliabilityReasons": hit_messages,
                "age": age,
                "gender": convert_null(panel_dict.get('ì„±ë³„')),
                "occupation": convert_null(panel_dict.get('ì§ì—…')),
                "residence": convert_null(panel_dict.get('ì§€ì—­')),
                "district": convert_null(panel_dict.get('ì§€ì—­êµ¬')),
                "maritalStatus": convert_null(panel_dict.get('ê²°í˜¼ì—¬ë¶€')),
                "education": convert_null(panel_dict.get('ìµœì¢…í•™ë ¥')),
                "job": convert_null(panel_dict.get('ì§ì—…')),
                "role": convert_null(panel_dict.get('ì§ë¬´')),
                "personalIncome": convert_null(panel_dict.get('ì›”í‰ê· _ê°œì¸ì†Œë“')),
                "householdIncome": convert_null(panel_dict.get('ì›”í‰ê· _ê°€êµ¬ì†Œë“')),
                "children": panel_dict.get('ìë…€ìˆ˜') if panel_dict.get('ìë…€ìˆ˜') is not None else 0,
                "familySize": convert_null(panel_dict.get('ê°€ì¡±ìˆ˜')),
                "phoneModel": convert_null(panel_dict.get('íœ´ëŒ€í°_ëª¨ë¸')),
                "phoneBrand": convert_null(panel_dict.get('íœ´ëŒ€í°_ë¸Œëœë“œ')),
                "carOwnership": convert_null(panel_dict.get('ì°¨ëŸ‰ì—¬ë¶€'), 'ì—†ìŒ'),
                "carBrand": convert_null(panel_dict.get('ìë™ì°¨_ì œì¡°ì‚¬')),
                "carModel": convert_null(panel_dict.get('ìë™ì°¨_ëª¨ë¸')),
                "smokingExperience": panel_dict.get('í¡ì—°ê²½í—˜') or [],
                "drinkingExperience": panel_dict.get('ìŒìš©ê²½í—˜_ìˆ ') or [],
                "ownedProducts": panel_dict.get('ë³´ìœ ì „ì œí’ˆ') or [],
                "lifestylePatterns": lifestyle_dict,
                "birthYear": birth_year,
                "_text_description": panel_to_text(panel_dict),
            }
            panels.append(panel)
        
        panels.sort(key=lambda x: x['reliability'], reverse=True)
        
        words = []
        keywords = query.split()
        for keyword in keywords:
            if len(keyword) > 1:
                words.append({"text": keyword, "value": 10})
        
        logging.info(f"ğŸ‰ ê²€ìƒ‰ ì™„ë£Œ: {len(panels)}ê°œ íŒ¨ë„")
        
        return jsonify({
            "panels": panels,
            "words": words
        })
        
    except Exception as e:
        logging.error(f"ğŸ’¥ ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
        traceback.print_exc()
        return jsonify({
            "error": "ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            "detail": str(e)
        }), 500

@app.route('/api/common-characteristics', methods=['POST'])
def common_characteristics():
    """íŒ¨ë„ë“¤ì˜ ê³µí†µ íŠ¹ì„± ë¶„ì„"""
    try:
        data = request.get_json()
        panels = data.get('panels', [])
        
        if not panels or len(panels) == 0:
            return jsonify({"error": "ë¶„ì„í•  íŒ¨ë„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}), 400
        
        logging.info(f"ğŸ” ê³µí†µ íŠ¹ì„± ë¶„ì„: {len(panels)}ê°œ íŒ¨ë„")
        
        keyword_counter = {}
        
        for panel in panels:
            gender = panel.get('gender')
            if gender and gender != 'ë¬´ì‘ë‹µ':
                keyword_counter[gender] = keyword_counter.get(gender, 0) + 1
            
            residence = panel.get('residence')
            if residence and residence != 'ë¬´ì‘ë‹µ':
                keyword_counter[residence] = keyword_counter.get(residence, 0) + 1
            
            job = panel.get('job')
            if job and job != 'ë¬´ì‘ë‹µ':
                keyword_counter[job] = keyword_counter.get(job, 0) + 1
            
            age = panel.get('age')
            if age:
                if age < 20:
                    age_group = '10ëŒ€'
                elif age < 30:
                    age_group = '20ëŒ€'
                elif age < 40:
                    age_group = '30ëŒ€'
                elif age < 50:
                    age_group = '40ëŒ€'
                elif age < 60:
                    age_group = '50ëŒ€'
                else:
                    age_group = '60ëŒ€ ì´ìƒ'
                keyword_counter[age_group] = keyword_counter.get(age_group, 0) + 1
            
            income = panel.get('personalIncome')
            if income and income != 'ë¬´ì‘ë‹µ':
                keyword_counter[income] = keyword_counter.get(income, 0) + 1
        
        top_keywords = sorted(
            keyword_counter.items(), 
            key=lambda x: x[1], 
            reverse=True
        )[:5]
        
        keywords = [
            {"keyword": k, "count": v} 
            for k, v in top_keywords
        ]
        
        total_count = len(panels)
        avg_age = sum(p.get('age', 0) for p in panels) / total_count if total_count > 0 else 0
        
        gender_dist = {}
        for p in panels:
            g = p.get('gender', 'ë¬´ì‘ë‹µ')
            gender_dist[g] = gender_dist.get(g, 0) + 1
        
        residence_dist = {}
        for p in panels:
            r = p.get('residence', 'ë¬´ì‘ë‹µ')
            if r != 'ë¬´ì‘ë‹µ':
                residence_dist[r] = residence_dist.get(r, 0) + 1
        
        summary_prompt = f"""ë‹¤ìŒì€ {total_count}ëª…ì˜ íŒ¨ë„ ë°ì´í„° ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤:

ê³µí†µ íŠ¹ì„± ìƒìœ„ 5ê°œ:
{chr(10).join([f'- {k["keyword"]}: {k["count"]}ëª…' for k in keywords])}

í‰ê·  ë‚˜ì´: {avg_age:.1f}ì„¸
ì„±ë³„ ë¶„í¬: {', '.join([f'{k} {v}ëª…' for k, v in gender_dist.items()])}
ì£¼ìš” ê±°ì£¼ì§€: {', '.join([f'{k} {v}ëª…' for k, v in sorted(residence_dist.items(), key=lambda x: x[1], reverse=True)[:3]])}

ì´ íŒ¨ë„ ì§‘ë‹¨ì˜ íŠ¹ì§•ì„ 2-3ë¬¸ì¥ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”. 
ë§ˆì¼€íŒ…ì´ë‚˜ íƒ€ê²ŸíŒ… ê´€ì ì—ì„œ ìœ ìš©í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”."""

        message = client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=512,
            messages=[
                {"role": "user", "content": summary_prompt}
            ]
        )
        
        summary = message.content[0].text.strip()
        
        logging.info(f"âœ… ê³µí†µ íŠ¹ì„± ë¶„ì„ ì™„ë£Œ: {len(keywords)}ê°œ í‚¤ì›Œë“œ")
        
        return jsonify({
            "keywords": keywords,
            "summary": summary
        })
        
    except Exception as e:
        logging.error(f"ğŸ’¥ ê³µí†µ íŠ¹ì„± ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        traceback.print_exc()
        return jsonify({
            "error": "ê³µí†µ íŠ¹ì„± ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            "detail": str(e)
        }), 500

# í‚¤ì›Œë“œ í›„ë³´êµ°
KEYWORD_POOL = [
    '20ëŒ€ ì—¬ì„±', 'ì„œìš¸ ê±°ì£¼', 'ì§ì¥ì¸', 'ì›”ì†Œë“ 300ë§Œì›', 'ë¯¸í˜¼', 'ëŒ€ì¡¸', 'ITì—…ê³„',
    'ë² ì´ë¹„ë¶ ì„¸ëŒ€', 'í”„ë¦¬ëœì„œ', 'ìš´ë™ ì¢‹ì•„í•¨', '30ëŒ€ ë‚¨ì„±', 'ë¶€ë™ì‚° íˆ¬ì', 'ê²½ê¸°ë„',
    'ì—¬í–‰', 'ìœ¡ì•„', 'ë¶€ëª¨'
]

@app.route('/api/related_keywords', methods=['POST'])
def related_keywords():
    data = request.get_json()
    user_query = data.get('query', '').strip()
    top_n = int(data.get('top_n', 7))
    if not user_query:
        return jsonify({'keywords': []})
    
    cand_emb = kure_model.encode(KEYWORD_POOL, convert_to_tensor=True)
    q_emb = kure_model.encode(user_query, convert_to_tensor=True)
    sims = util.pytorch_cos_sim(q_emb, cand_emb).cpu().numpy().flatten()
    indices = sims.argsort()[::-1][:top_n]
    related = [
        {'text': KEYWORD_POOL[i], 'similarity': float(sims[i])} for i in indices
    ]
    return jsonify({'keywords': related})

@app.route('/api/export-csv', methods=['POST'])
def export_csv():
    """íŒ¨ë„ ë°ì´í„°ë¥¼ CSVë¡œ ë‚´ë³´ë‚´ê¸°"""
    try:
        import csv
        from io import StringIO
        from flask import make_response
        
        data = request.get_json()
        panels = data.get('panels', [])
        
        if not panels:
            return jsonify({"error": "ë‚´ë³´ë‚¼ íŒ¨ë„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}), 400
        
        output = StringIO()
        
        headers = [
            'MB_SN', 'íŒ¨ë„ë²ˆí˜¸', 'ì‹ ë¢°ë„', 'ê°ì ì‚¬ìœ ',
            'ì„±ë³„', 'ë‚˜ì´', 'ì¶œìƒë…„ë„', 'ê±°ì£¼ì§€', 'ì§€ì—­êµ¬',
            'ê²°í˜¼ì—¬ë¶€', 'ìë…€ìˆ˜', 'ê°€ì¡±ìˆ˜', 'ìµœì¢…í•™ë ¥', 'ì§ì—…', 'ì§ë¬´',
            'ì›”í‰ê· _ê°œì¸ì†Œë“', 'ì›”í‰ê· _ê°€êµ¬ì†Œë“',
            'íœ´ëŒ€í°_ë¸Œëœë“œ', 'íœ´ëŒ€í°_ëª¨ë¸',
            'ì°¨ëŸ‰ì—¬ë¶€', 'ìë™ì°¨_ì œì¡°ì‚¬', 'ìë™ì°¨_ëª¨ë¸',
            'í¡ì—°ê²½í—˜', 'ìŒì£¼ê²½í—˜', 'ë³´ìœ ì œí’ˆ'
        ]
        
        writer = csv.DictWriter(
            output, 
            fieldnames=headers,
            quoting=csv.QUOTE_ALL,
            lineterminator='\n'
        )
        writer.writeheader()
        
        for panel in panels:
            def format_list(value):
                if value is None:
                    return '-'
                if isinstance(value, list):
                    if len(value) == 0:
                        return '-'
                    return ' / '.join(str(v) for v in value)
                return str(value) if value else '-'
            
            writer.writerow({
                'MB_SN': panel.get('mbSn', '-'),
                'íŒ¨ë„ë²ˆí˜¸': panel.get('id', '-'),
                'ì‹ ë¢°ë„': f"{panel.get('reliability', 0)}%",
                'ê°ì ì‚¬ìœ ': ' / '.join(panel.get('reliabilityReasons', [])) if panel.get('reliabilityReasons') else '-',
                'ì„±ë³„': panel.get('gender', '-'),
                'ë‚˜ì´': f"ë§Œ {panel.get('age', '-')}ì„¸" if panel.get('age') else '-',
                'ì¶œìƒë…„ë„': panel.get('birthYear', '-'),
                'ê±°ì£¼ì§€': panel.get('residence', '-'),
                'ì§€ì—­êµ¬': panel.get('district', '-'),
                'ê²°í˜¼ì—¬ë¶€': panel.get('maritalStatus', '-'),
                'ìë…€ìˆ˜': panel.get('children', 0),
                'ê°€ì¡±ìˆ˜': panel.get('familySize', '-'),
                'ìµœì¢…í•™ë ¥': panel.get('education', '-'),
                'ì§ì—…': panel.get('job', '-'),
                'ì§ë¬´': panel.get('role', '-'),
                'ì›”í‰ê· _ê°œì¸ì†Œë“': panel.get('personalIncome', '-'),
                'ì›”í‰ê· _ê°€êµ¬ì†Œë“': panel.get('householdIncome', '-'),
                'íœ´ëŒ€í°_ë¸Œëœë“œ': panel.get('phoneBrand', '-'),
                'íœ´ëŒ€í°_ëª¨ë¸': panel.get('phoneModel', '-'),
                'ì°¨ëŸ‰ì—¬ë¶€': panel.get('carOwnership', '-'),
                'ìë™ì°¨_ì œì¡°ì‚¬': panel.get('carBrand', '-'),
                'ìë™ì°¨_ëª¨ë¸': panel.get('carModel', '-'),
                'í¡ì—°ê²½í—˜': format_list(panel.get('smokingExperience')),
                'ìŒì£¼ê²½í—˜': format_list(panel.get('drinkingExperience')),
                'ë³´ìœ ì œí’ˆ': format_list(panel.get('ownedProducts')),
            })
        
        csv_content = output.getvalue()
        output.close()
        
        csv_bytes = '\ufeff' + csv_content
        
        response = make_response(csv_bytes.encode('utf-8'))
        response.headers['Content-Type'] = 'text/csv; charset=utf-8'
        response.headers['Content-Disposition'] = 'attachment; filename*=UTF-8\'\'%ED%8C%A8%EB%84%90%EB%8D%B0%EC%9D%B4%ED%84%B0.csv'
        
        logging.info(f"âœ… CSV ë‚´ë³´ë‚´ê¸° ì™„ë£Œ: {len(panels)}ê°œ íŒ¨ë„")
        
        return response
        
    except Exception as e:
        logging.error(f"ğŸ’¥ CSV ë‚´ë³´ë‚´ê¸° ì˜¤ë¥˜: {str(e)}")
        traceback.print_exc()
        return jsonify({
            "error": "CSV ë‚´ë³´ë‚´ê¸° ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            "detail": str(e)
        }), 500

if __name__ == '__main__':
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s [%(levelname)s] %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    app.run(host='0.0.0.0', port=5000, debug=True)